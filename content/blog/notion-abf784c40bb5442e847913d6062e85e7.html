---
title: Keeping track of database changes and when it can be useful
tags:
  - aws
  - databases
  - devops
date: '2022-09-21T20:42:50.910Z'
slug: keeping-track-of-database-changes-and-when-it-can-be-useful
draft: false
---

<article id="abf784c4-0bb5-442e-8479-13d6062e85e7" class="page sans"><div class="page-body"><figure id="e641f197-f50c-48cd-84fa-e424003aa182" class="image"><a href="https://images.unsplash.com/photo-1591696205602-2f950c417cb9?ixlib=rb-1.2.1&amp;q=80&amp;cs=tinysrgb&amp;fm=jpg&amp;crop=entropy"><img src="https://images.unsplash.com/photo-1591696205602-2f950c417cb9?ixlib=rb-1.2.1&amp;q=80&amp;cs=tinysrgb&amp;fm=jpg&amp;crop=entropy"></a></figure><p id="85b1f801-997f-44dc-bf58-a7703c8f4792" class="">
</p><blockquote id="6944f64b-40ec-4a9b-aab8-e3a6ae770768" class=""><em>My task was simple - we had a Postgres database and a data science team that needed to consume changes from the database to update their internal datasets.
But how on earth would I do that? </em>ü§∑üèª‚Äç‚ôÇÔ∏è&nbsp;<em>Luckily, my colleagues brought some light into this mysterious database world but I still had to (wanted) read a lot to understand it better and make sure I did it right.</em></blockquote><p id="f3cdfbcc-fc33-438c-835f-32705855d7ac" class="">
</p><p id="153e8422-d1c7-45ce-95a5-9dab72ae0ef0" class="">Today almost every application needs some place where to store data. Most of the time this place is a database and often it plays a crucial role in the whole system. There are many different databases available, each designed for a specific purpose. They can be hosted locally on a computer, somewhere in a data center, or in a cloud, so-called <strong>managed database</strong> instances. These are especially useful when we don‚Äôt want to take care of maintenance, data durability, and availability.</p><p id="0bd53825-a76c-411d-a653-166e168ad5bc" class="">Moreover, the other big benefit of managed databases is <strong>scalability</strong>. This is very important when an application starts getting users. We, as developers, have to make sure that it will withstand the incoming traffic. There is a bunch of techniques to achieve this as it is a very complex and difficult task. When the database begins to run out of resources, such as lack of free memory (RAM), overutilized CPU, or reaching a storage limit, some action is necessary. The easiest solution is raising the resource limits, i.e. providing more RAM, better CPU, or more disk space. This is known as <strong>vertical scaling</strong>, you just add more resources to a single (database) machine. </p><p id="ed0bdf6f-10b2-4232-9fd7-cf1ec73ea077" class="">However, this is not sustainable in the long term because sooner or later the database might hit its limits again, and further scaling could become very expensive or even not physically possible. That‚Äôs where <strong>horizontal scaling</strong> comes into play. Instead of increasing the physical parameters of a single machine, we add multiple smaller machines that can split the load.</p><p id="f2a036d6-b5d1-4ab2-93ab-352b93173b44" class="">In some scenarios, where there is too much data being stored, <a href="https://www.digitalocean.com/community/tutorials/understanding-database-sharding"><strong>sharding</strong></a><strong> </strong>might come in very handy, where data is partitioned among several databases but this is out of the scope of this article.</p><p id="56d01332-4a8d-491c-bb16-ba942a123f99" class="">Another important thing is the concept of <strong>replication </strong>which is a key to ensuring <strong>data persistence</strong> but it also helps with offloading the main database server by introducing a <strong>read replica </strong>that is used for reading queries.</p><p id="53478277-8fb5-494b-818f-d3f68af21b62" class="">This is what we will focus on in this article - a really high-level description of <strong>how replication works</strong>, <strong>the types of replication</strong>, and how we can leverage them. </p><h2 id="49fa3e20-9701-4837-825c-2654dc105375" class=""><strong>What is replication?</strong></h2><blockquote id="c0afad9b-e61d-43b6-94ea-56f4b8f92e15" class=""><em>‚Äú‚Ä¶sharing information so as to ensure consistency between redundant resources, such as&nbsp;software&nbsp;or&nbsp;hardware&nbsp;components, to improve </em><strong><em>reliability</em></strong><em>,&nbsp;</em><strong><em>fault-tolerance</em></strong><em>, or </em><strong><em>accessibility</em></strong><em>‚Ä¶‚Äù</em>
- Wikipedia</blockquote><p id="da41c49a-5721-4de4-b22d-262da479426c" class="">As we can see, replication is an essential and commonly used method that is, in short, supposed to help keep your application available to users. It does that by copying data into multiple machines so an application can continue working seamlessly if the main database becomes unavailable.</p><p id="172f079d-3df0-47d2-b102-98d9e4cc4ca4" class="">There are many <a href="https://www.postgresql.org/docs/13/different-replication-solutions.html">ways</a> to achieve this, from low-level solutions like<strong> sharing a disk</strong> or a network file system across machines, to <strong>shipping WAL logs </strong>(<em>we'll talk about WAL later</em>), having an <strong>SQL middleware</strong> that intercepts all queries and sends them to other servers, <strong>logical replication</strong> and more.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="a4d44e46-54bd-42f7-a9b6-db79864cd006"><div style="font-size:1.5em"><span class="icon">‚ÑπÔ∏è</span></div><div style="width:100%">It is important to keep in mind though, that there are plenty of different databases, some of them designed for a very specific use case, therefore not everything we mention can be applied to all of them. In this article, we are using <a href="https://www.postgresql.org/">Postgres</a> 13, which is a powerful, widely used relational database, that one would probably use most of the time.</div></figure><h3 id="5e82653e-1858-47ae-b3e4-a98d089b4b9a" class="">Logical replication</h3><p id="46b57868-0c2f-4298-a3ed-cad567d0a087" class="">While disk-based (also called <strong>physical</strong>) methods work on a binary level, where the exact block addresses are directly sent over (byte-by-byte replication), logical replication works with tables rather than raw database data. It replicates data objects and their changes based on their replication identity (usually a primary key).</p><p id="e20a4ebb-03e3-45a9-a58e-51fadaf65853" class="">It has many use cases such as,</p><ul id="a4a79486-b2c5-4324-82dc-558663a49729" class="bulleted-list"><li style="list-style-type:disc">replicating data between different major versions of PostgreSQL or different platforms (e.g. Linux to Windows)</li></ul><ul id="6616ffcc-d401-4bcb-a66d-4cdba74d980e" class="bulleted-list"><li style="list-style-type:disc">grouping multiple databases into one (e.g. for analytics)</li></ul><ul id="54249805-9bb4-4883-b22f-b191f45ab2aa" class="bulleted-list"><li style="list-style-type:disc">sharing a subset of the database with other users or systems</li></ul><ul id="3cd4b45f-5b08-47bb-8d21-5e8721199b9c" class="bulleted-list"><li style="list-style-type:disc">distributing database changes to subscribers in real-time</li></ul><p id="cc7969f4-70a2-41b6-8676-d1157960c67f" class="">However, it‚Äôs important to note that it <strong>only supports </strong><strong><a href="https://stackoverflow.com/a/44796508/4480179">DML operations</a></strong> (<code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>), therefore schema changes will not be replicated and the schema itself must be identified and defined beforehand.</p><p id="43b0f69a-abdc-4bd0-9819-f2297f6e19a8" class="">It uses a publisher/subscriber model which can be used as follows,</p><pre id="464f1883-6f9c-4158-afe8-5b20fce3fc4d" class="code"><code>CREATE PUBLICATION pub FOR TABLE users</code></pre><p id="3e346ae5-85fc-4f87-b948-b2a0b54626fa" class="">The p<strong>ublication</strong> is defined on a primary database and represents a set of changes generated from a table or multiple tables.</p><p id="799e6a17-b6dd-435a-bbb4-39fbb442d66a" class="">Then, on the secondary (replica) database you would create a <strong>subscription t</strong>hat specifies the connection to the main database and the set of publications to subscribe to.</p><pre id="a57aaddf-6cf9-48e6-aea5-736126df53de" class="code"><code>CREATE SUBSCRIPTION sub CONNECTION 'host=192.168.1.1 port=5432 user=foo dbname=bar password=xyz123' PUBLICATION pub</code></pre><p id="9bbda52c-acc2-46e3-a13d-67debdb2732d" class="">This way we can configure logical replication between two databases.</p><h3 id="42793162-25e1-46b2-b7e3-4aa88bc5fd01" class="">Logical decoding</h3><p id="bcc50197-a0e3-4b80-8d08-5f985569d3d8" class="">Logical decoding is very similar to logical replication but it provides an option to consume the changes to a database‚Äôs tables to <strong>external consumers</strong>. This could be a different kind of database, some business application, auditing software, etc.</p><p id="a8d472fe-fa2e-4e8b-bf07-da29918e17d9" class="">The data is stored using <strong>replication slots</strong>. A slot represents a stream of changes that can be replayed to a client in the order they were made on the origin server. You can think of it as an ordered list where a database pushes the changes and a consuming application on the other side reads those changes. Usually, there should be a separate replication slot for each consumer as the changes are wiped after reading(!)</p><p id="0b93b27a-9528-47e5-bf63-87ca93e4adbb" class="">The output format is defined by a plugin that you can set. There are several <a href="https://wiki.postgresql.org/wiki/Logical_Decoding_Plugins">plugins</a> available, that can process the WAL log and print out the results in a format that is desired and processable by a consumer application.</p><p id="795a29bb-de1d-4af7-bb2f-a8439551ca55" class="">There are two options for consuming the changes</p><ul id="fcc9e18c-1c2b-48f3-a42f-83d2e8b6756b" class="bulleted-list"><li style="list-style-type:disc">using special SQL functions for retrieving data, such as <code>pg_logical_slot_get_changes()</code></li></ul><ul id="13975e94-25c5-4c26-a1b4-870dd3c8c672" class="bulleted-list"><li style="list-style-type:disc">using a streaming protocol to get real-time events of database changes - this can be achieved by using <a href="https://www.postgresql.org/docs/current/app-pgrecvlogical.html"><code>pg_recvlogical</code></a> utility</li></ul><h3 id="bf05a3a2-ad9f-4abe-bb86-8dc10ac8883f" class=""><strong>Write-ahead log (WAL)</strong></h3><p id="134d24c3-2758-454d-a780-2745bdcef4e7" class="">So what the heck is this WAL anyway?</p><p id="b9a95953-0a19-4b4d-b1f1-3f62b1e7c38b" class="">In the Postgres database, all changes to data files must be recorded in the log file before they are written to the database. Only after this, a transaction is deemed to be committed (<a href="https://www.postgresql.org/docs/current/wal-async-commit.html">asynchronous commit</a>). This is a standard method for ensuring data integrity and durability as in the event of a database crash, all the changes can be reapplied to the database using the log.</p><p id="e50fe965-4350-40dd-99d0-7442de633bdf" class="">Following this procedure, the database doesn‚Äôt need to flush data pages to disk on every transaction commit which also improves the speed of transactions, as explained in the Postgres <a href="https://www.postgresql.org/docs/current/wal-intro.html">docs</a>:</p><blockquote id="afa6fa9b-e3d3-4c8a-9853-1c54a2419c7c" class=""><em>Using&nbsp;WAL results in a significantly reduced number of disk writes because only the log file needs to be flushed to disk to guarantee that a transaction is committed, rather than every data file changed by the transaction. The log file is written sequentially, so the cost of syncing the log is much less than the cost of flushing the data pages</em></blockquote><p id="41106757-1eec-4874-81e4-b32ccd317895" class="">Now, that we talked about what the WAL is, you can get a better idea of how the replication process works. As the database keeps these log files, they can be just sent to another machine and applied there.</p><h2 id="d089bfd3-c54d-4611-9cc7-825f0e01ccf5" class=""><strong>Configuring the database</strong></h2><p id="40acd128-46d2-454e-a797-9b36c5d636c3" class="">As said in the beginning, we needed to configure a 3rd party service to consume updates from the main database, therefore we had to use logical decoding which allows you to create a replication slot with a given output formatting plugin and consume the changes. We used a popular plugin <code>wal2json</code> which takes the WAL records and converts them into a JSON format, making them easily processable by third-party applications.</p><p id="6a6b7e45-37ad-48fc-8c3f-a23eaf2bf06b" class="">In order to do this, we first needed to grant replication permissions to the database user. As we were using an RDS instance in AWS, the command looked like this:</p><pre id="b1265ed1-da43-4b06-b516-c4bba3246826" class="code"><code>GRANT rds_replication TO myuser</code></pre><p id="c93aeb52-e126-4d4b-bb1a-007bdc8fbc4b" class="">After that, we needed to configure some Postgres parameters so the replication could start. Normally, we‚Äôd look for a config file like <code>postgresql.conf</code> ‚Äî but since we were on a managed database, we used the so-called Parameter Group where we could easily configure all the necessary values in the UI.</p><ul id="1bf4d62f-d432-43be-8349-a2ecd03d513f" class="bulleted-list"><li style="list-style-type:disc"><code>rds.logical_replication</code> ‚áí  <code>1</code> This is the first parameter that has to be set to <code>1</code> in order to enable logical replication</li></ul><ul id="ca38ad87-847d-4e67-9349-d8cf702bc279" class="bulleted-list"><li style="list-style-type:disc"><code>wal_level</code> ‚áí This has to be set to <code>logical</code> but it is handled automatically by AWS once you enable <code>rds.logical_replication</code>, (<a href="https://postgresqlco.nf/doc/en/param/wal_level/">read more</a>)</li></ul><ul id="86831fc3-b054-4f2f-81e9-324773e10fae" class="bulleted-list"><li style="list-style-type:disc"><code>max_slot_wal_keep_size</code> ‚áí <code>20000</code> This value specifies how much data can be stored in a replication slot before it starts recycling the memory.
It is specified in MB and you should think of your database use case, the amount of data written, and set a proper value. If the number is <strong>too low</strong> and your database <strong>writes a lot</strong> of changes the slot might <strong>get recycled too soon</strong> and if you don‚Äôt read all the changes before the databases (or 3rd party system) get <strong>out of sync,</strong> you will need to do a full sync again! This is something that you need to test and see what‚Äôs the best value for your needs.
Important to mention, that this value is set to <code>-1</code> <strong>by default</strong> (!) which means unlimited storage size. If you are not careful your slot might end up <strong>taking up all the available free storage</strong> on the database resulting in <strong>database unavailability </strong>as it runs out of memory ‚ö†Ô∏è&nbsp;(<a href="https://postgresqlco.nf/doc/en/param/max_slot_wal_keep_size/">read more</a>)</li></ul><p id="68c6b749-123c-4f37-9ada-d68081cfea3c" class="">Beware, that these changes will require a <strong>database restart</strong>!</p><p id="b3890ccc-50e7-4495-a740-e95c02188561" class="">That is all that needs to be configured to have logical decoding working in Postgres. Naturally, there are many more parameters that can be set to adjust this behavior but we were okay with their default values for the time being.</p><p id="fa9a4eff-5ee4-4673-a246-01259f0ef5f1" class="">Other interesting parameters that I was looking at were <code>max_replication_slots</code> and <code>max_wal_senders</code> but eventually, we didn‚Äôt need to change them and the default values sufficed.</p><p id="3e86b046-16b8-4799-bb64-efec79a10d5e" class="">One more thing that is crucial to keep in mind is that <strong>slots keep data until it‚Äôs read </strong>by a consumer. Once the data is read, it is automatically deleted from the slot. This means that if you don‚Äôt use a replication slot (anymore) it should be dropped, otherwise there will be unnecessary data piling up and filling the storage!</p><p id="3cf4ffb1-63fe-42cd-a84a-013900e482ef" class="">There is even a warning in the <a href="https://www.postgresql.org/docs/current/logicaldecoding-explanation.html#LOGICALDECODING-REPLICATION-SLOTS">official docs</a></p><blockquote id="5402118f-754a-4ca1-a890-d85188ea4323" class=""><em>Replication slots persist across crashes and know nothing about the state of their consumer(s). They will prevent removal of required resources even when there is no connection using them. This consumes storage because neither required WAL nor required rows from the system catalogs can be removed by&nbsp;</em><em><code>VACUUM</code></em><em>as long as they are required by a replication slot. In extreme cases this could cause the database to shut down to prevent transaction ID wraparound (see&nbsp;</em><em><a href="https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-WRAPAROUND"><strong>Section&nbsp;25.1.5</strong></a></em><em>). So if a slot is no longer required it should be dropped.</em></blockquote><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="7796e05a-81ce-4c95-8e03-203af14e61de"><div style="font-size:1.5em"><span class="icon">‚ÑπÔ∏è</span></div><div style="width:100%">If you want to learn more about the specific Postgres configuration parameters, I really recommend <a href="http://postgresqlco.nf/">postgresqlco.nf</a> or the official <a href="https://www.postgresql.org/docs/14/index.html">Postgres docs</a> which are very well written and their explanation of the various concepts are easy to read and understand üíØ</div></figure><h3 id="2da87bb9-2191-4762-b928-e004b061d4a5" class="">Consuming changes</h3><p id="b650a5ba-ee1a-40a9-9469-090ccfecbeb1" class="">Now that we got our database configured properly, we can finally start consuming database changes. In order to do so, we need to <strong>create a replication slot</strong> first.<strong> </strong>We can do that by calling a function <code>pg_create_logical_replication_slot</code>.</p><pre id="f9f8f2d1-036f-48dc-90ba-5569582d43bf" class="code"><code>SELECT * FROM pg_create_logical_replication_slot('my_replication_slot', 'wal2json')</code></pre><p id="9723e626-e776-403e-a7bd-330bfb4eff1e" class="">This will create a replication slot with the name <code>my_replication_slot</code> and set <code>wal2json</code> as the output formatting plugin.</p><p id="c804f9de-f3dd-4ecc-bf10-f178b0aee61e" class="">To verify that the slot got created we can send a simple SQL query.</p><pre id="f576cc95-088d-406a-9a91-539bac0bedd2" class="code"><code>SELECT * FROM pg_catalog.pg_replication_slots</code></pre><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="f77fb152-7d6a-4921-af0c-24ba95e2baf4"><div style="font-size:1.5em"><span class="icon">‚ÑπÔ∏è</span></div><div style="width:100%">Please note, that in order to use <code>wal2json</code> plugin, you might need to <a href="https://github.com/eulerto/wal2json#build-and-install">install</a> it into your database first.
However, if you use AWS RDS (or maybe other cloud providers as well) the plugin is already installed and ready, even though <a href="https://github.com/eulerto/wal2json/issues/75">it‚Äôs not showing</a> in the <code>pg_extension</code> table.</div></figure><p id="344c5de7-74f7-47f9-b348-9b0316e2c4e0" class="">Now that we have the slot created, let‚Äôs see how it looks.</p><p id="284db597-a250-432b-b13f-4bb469609c51" class="">Let‚Äôs try to do a simple <code>INSERT</code> query:</p><pre id="848a099a-9746-4979-88a2-900c80585552" class="code"><code>INSERT INTO users (id, email, role, name)
VALUES (
	'847be54f-3a82-4591-a293-023ea15b2962',
	'john.wick@example.com',
	'user',
	'John Wick'
)</code></pre><p id="93a97ea9-983d-4f3e-9c1d-3255b4433fda" class="">Now, we can take a peek at what has been logged by calling </p><pre id="617e8221-6fab-4b1d-ba41-22816d6408b5" class="code"><code>SELECT * FROM pg_logical_slot_peek_changes('my_replication_slot', NULL, NULL, 'include-xids', '0')</code></pre><p id="fec93492-9689-4eed-b810-98c4cf1f2233" class="">which will return our inserted data üéâ. </p><pre id="5c2fbaab-6d0d-4b37-adec-d095a272fbff" class="code"><code>{
   "change":[
      {
         "kind":"insert",
         "schema":"public",
         "table":"users",
         "columnnames":[
            "id",
            "email",
            "role",
            "name"
         ],
         "columntypes":[
            "uuid",
            "character varying(255)",
            "character varying(255)",
            "character varying(255)"
         ],
         "columnvalues":[
            "847be54f-3a82-4591-a293-023ea15b2962",
            "john.wick@example.com",
            "user",
            "John Wick"
         ]
      }
   ]
}</code></pre><p id="f7f78e69-f4b6-4450-b3a2-31b666194cb9" class="">Peeking is good for testing to see if everything works and the changes are propagating but in a real scenario, we would use a different function </p><pre id="d5854e9e-1996-47d1-8fdc-9f62a061529d" class="code"><code>SELECT * FROM pg_logical_slot_get_changes('my_replication_slot', NULL, NULL, 'include-xids', '0') </code></pre><p id="95087346-65a2-4da4-9626-91840debcbc3" class="">The difference here is that, as we mentioned, changes are deleted from the slot once the consumer reads them so this function is the one you will want to use. Now, if you try to run the same query again, you will notice there are no results so everything worked as expected.</p><p id="0e9b8941-57bb-4b7f-9043-f0195ff451e5" class="">Now you can just connect your consumer application to the database and start processing all changes üöÄ</p><p id="adf04e53-857a-4371-ab45-69540d2f6c34" class="">If we don‚Äôt need the slot anymore we can just drop it.</p><pre id="408f98e3-aa83-493e-8f3f-5c0416a9d2f9" class="code"><code>SELECT * FROM pg_drop_replication_slot('my_replication_slot')</code></pre><h2 id="24db4948-2218-4ebf-a149-2e83d6881bc9" class=""><strong>Conclusion</strong></h2><p id="fff427d3-465c-4934-ac04-fede436239bc" class="">In this article, we learned what replication is, that there are many techniques to achieve it and that it can be used not only for keeping data in sync between databases but also even with 3rd party systems.</p><p id="c85e4c05-8836-4611-9229-c6d2c877e84f" class="">We dove a little into the internals of how databases store all the changes in a specific log file (WAL) and that this log file can be also used for logical decoding which with a set of various output plugins makes a very powerful tool for data visibility.</p><p id="d1dc4ff9-97fb-4cc9-836c-c10d5d14e08f" class="">Now we know how this decoding works and that it is important to read the docs properly (or get advice from an experienced colleague üòâ) and investigate which parameters should be set in order not to get surprised by an unresponsive database due to a lack of memory. Moreover, having monitoring in place and visibility over what‚Äôs going on is always more than desired.</p><p id="36a7fef0-e747-47e1-9848-1423ca5b26e5" class="">
</p><hr id="45f7779d-88a1-4180-b641-5c58874b7c7b"><p id="f0493470-31dc-4395-a305-141752ae44ac" class="">I would like to thank my colleagues <a href="https://www.linkedin.com/in/janhybl">Honza</a> and <a href="https://www.linkedin.com/in/jozefreginac">Jozef</a>, who helped me understand the details and provided some useful tips and insights.</p></div></article>